<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>stacked debert_all attention in incomplete data for text classification | Adam&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="NLP" />
  
  
  
  
  <meta name="description" content="任务分析不完整数据问题通常认为是一个reconstruction或imputation任务 通常与missing number imputation有关 历史工作针对缺失数据插补  Vincent提出将输入映射到有意义的表示上，从而重建出clean data 其他：predictive mean matching, random forest, Support Vector Machine (SV">
<meta property="og:type" content="article">
<meta property="og:title" content="Stacked DeBERT_All Attention in Incomplete Data for Text Classification">
<meta property="og:url" content="http://adamfocus.github.io/2020/07/30/Stacked%20DeBERT%20All%20Attention%20in%20Incomplete%20Data%20for%20Text%20Classification%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Adam&#39;s Blog">
<meta property="og:description" content="任务分析不完整数据问题通常认为是一个reconstruction或imputation任务 通常与missing number imputation有关 历史工作针对缺失数据插补  Vincent提出将输入映射到有意义的表示上，从而重建出clean data 其他：predictive mean matching, random forest, Support Vector Machine (SV">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/22/UHSF7F.jpg">
<meta property="og:image" content="g:/MyBlog/AdamFocus.github.io/img/TTS-STT对比.jpg">
<meta property="article:published_time" content="2020-07-30T05:00:00.000Z">
<meta property="article:modified_time" content="2021-09-27T14:00:53.073Z">
<meta property="article:author" content="Adam Focus">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/07/22/UHSF7F.jpg">
  

  

  <link rel="icon" href="/css/images/avatar.jpg">
  <link rel="apple-touch-icon" href="/css/images/avatar.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("/css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("/css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("/css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="/js/jquery-3.1.1.min.js"></script>

  
<script src="/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >

  
    
<link rel="stylesheet" href="/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/css/header-post.css" >
  

  
  
  

<meta name="generator" content="Hexo 5.4.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="border-width: 0;">
                <p>Adam&#39;s Blog</p>
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">首页</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">归档</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">关于</a> </li>
                
                  <li><div id="search-form-wrap">

    <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="index.search"><button type="submit" class="search-form-submit"> </button><input type="hidden" name="sitesearch" value="http://adamfocus.github.io"></form>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-Stacked DeBERT All Attention in Incomplete Data for Text Classification阅读笔记" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      Stacked DeBERT_All Attention in Incomplete Data for Text Classification
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2020/07/30/Stacked%20DeBERT%20All%20Attention%20in%20Incomplete%20Data%20for%20Text%20Classification%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="article-date">
	  <time datetime="2020-07-30T05:00:00.000Z" itemprop="datePublished">2020-07-30</time>
	</a>

      
    <a class="article-category-link" href="/categories/learning/">learning</a>

      
      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="任务分析"><a href="#任务分析" class="headerlink" title="任务分析"></a>任务分析</h3><p>不完整数据问题通常认为是一个reconstruction或imputation任务</p>
<p>通常与missing number imputation有关</p>
<h3 id="历史工作"><a href="#历史工作" class="headerlink" title="历史工作"></a>历史工作</h3><p>针对缺失数据插补</p>
<ol>
<li>Vincent提出将输入映射到有意义的表示上，从而重建出clean data</li>
<li>其他：predictive mean matching, random forest, Support Vector Machine (SVM) and Multiple imputation by Chained Equations (MICE),</li>
</ol>
<h3 id="本文工作"><a href="#本文工作" class="headerlink" title="本文工作"></a>本文工作</h3><p>面向tweets和语音转文本生成的句子</p>
<p>利用bert和去除噪声策略来解决不完全意图和情感分析</p>
<p>实现了Stacked Denoising BERT</p>
<p>obtaining richer input representations from input tokens by stacking denoising transformers on an embedding layer with vanilla transformers</p>
<p>（embedding层和vanilla transformer层用于获取输入的中间特征，denoising tranformers再从中提取出特征）</p>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>嵌入层    +    vanilla transformer层（conventional bidirectional transformers）+ denoising bidirectional transformers</p>
<p><img src="https://s1.ax1x.com/2020/07/22/UHSF7F.jpg" alt="UHSF7F.jpg"></p>
<h4 id="1-常规Bert层"><a href="#1-常规Bert层" class="headerlink" title="1.常规Bert层"></a>1.常规Bert层</h4><p>训练时在不完整的文本分类语料库上微调</p>
<ul>
<li>预处理：小写化单词并标记、使用[CLS] [SEP]进行标记</li>
<li>embedding层与bert相同：</li>
</ul>
<h4 id="2-Denoising-transformer："><a href="#2-Denoising-transformer：" class="headerlink" title="2.Denoising transformer："></a>2.Denoising transformer：</h4><ul>
<li><p>多层感知机堆叠：</p>
<p>设置成两组”三层”，每层有两个隐藏层</p>
<p><strong>过程</strong>：</p>
<ul>
<li><p>第一组：将$$h_{inc}$$压缩成潜在空间表示，提取特征转换成低维向量$$z_1,z_2,z$$</p>
<p>分别为($$N_{bs}$$,128,128), (Nbs,32,128),(Nbs,12,128)维</p>
<p>$$N_{bs}$$为batch size</p>
</li>
<li><p>第二组：将$$z_1,z_2,z$$转换成$$h_{rec1},h_{rec2},h_{rec}$$</p>
</li>
<li><p>将重建的向量$$h_{rec}$$与完整的向量$$h_{comp}$$借助均方差损失函数比较</p>
<p>$$L(h_{rec},h_{comp})=\frac{1}{N_{bs}}\sum_{i=1}^n(h_{rec}-h_{comp})^2$$</p>
</li>
</ul>
<p>提取更加抽象和有意义的隐藏特征向量，来重建缺失的词嵌入</p>
<p>训练在==sentence embedding==上进行，将不完全数据作为输入，将对应的完全数据$$h_{comp}$$作为target</p>
<p> Both input and target are obtained after applying the embedding layers and the vanilla transformers, and have shape (Nbs,768,128), where Nbsis the batch size, 768 is the original BERT embedding size for a single token, and 128 is the maximum sequence length in a sentence.</p>
</li>
<li><p>双向Transformer：</p>
<p>将上面生成的embedding输入该层，改进嵌入表示</p>
</li>
</ul>
<h4 id="3-feedforward-network-softmax-激活函数"><a href="#3-feedforward-network-softmax-激活函数" class="headerlink" title="3.feedforward network/softmax 激活函数"></a>3.feedforward network/softmax 激活函数</h4><h3 id="使用的数据集"><a href="#使用的数据集" class="headerlink" title="使用的数据集"></a>使用的数据集</h3><h4 id="1-Twitter-Sentiment-Classification"><a href="#1-Twitter-Sentiment-Classification" class="headerlink" title="1. Twitter Sentiment Classification"></a>1. Twitter Sentiment Classification</h4><p>[Kaggle’s two-class Sentiment140 dataset][<a target="_blank" rel="noopener" href="https://www.kaggle.com/kazanova/sentiment140]">https://www.kaggle.com/kazanova/sentiment140]</a></p>
<p>错误类型：</p>
<table>
<thead>
<tr>
<th align="center">mistake</th>
<th align="center">examples</th>
</tr>
</thead>
<tbody><tr>
<td align="center">spelling</td>
<td align="center">“teh” (the), “correclty” (correctly), “teusday” (Tuesday)</td>
</tr>
<tr>
<td align="center">Casual pronunciation</td>
<td align="center">“wanna” (want to), “dunno” (don’t know)</td>
</tr>
<tr>
<td align="center">Abbreviation</td>
<td align="center">“Lit” (Literature), “pls” (please), “u” (you), “idk” (I don’t know)</td>
</tr>
<tr>
<td align="center">Repeteated letters</td>
<td align="center">thursdayyyyyy”, “sleeeeeeeeeep”</td>
</tr>
<tr>
<td align="center">Onomatopoeia</td>
<td align="center">“Woohoo”, “hmmm”, “yaay”</td>
</tr>
<tr>
<td align="center">Others</td>
<td align="center">“im” (I’m), “your/ur” (you’re), “ryt” (right)</td>
</tr>
</tbody></table>
<p>使用人工标注正确信息</p>
<p>最终：</p>
<p>一共300条samples（只使用了250？）</p>
<ul>
<li>训练：200sentences，100p，100n</li>
<li>evaluate：50samples，25p，25n</li>
</ul>
<h4 id="2-Chatbot-Natural-Language-Unerstanding-NLU-Evaluation-Corpus"><a href="#2-Chatbot-Natural-Language-Unerstanding-NLU-Evaluation-Corpus" class="headerlink" title="2.Chatbot Natural Language Unerstanding (NLU) Evaluation Corpus"></a>2.Chatbot Natural Language Unerstanding (NLU) Evaluation Corpus</h4><p>Intent Classification from Text with STT Error</p>
<p>对拥有完整句子和意图标签的语料库进行TTS和STT处理，从而获取带有STT错误的不完整句子。</p>
<p>原始数据集：100train 106test</p>
<p>处理过程：</p>
<ul>
<li><p>TTS处理：使用gtts库[<a target="_blank" rel="noopener" href="https://pypi.org/project/gTTS/]%E5%92%8Cmacsay%E5%BA%93[https://ss64.com/osx/say.html]">https://pypi.org/project/gTTS/]和macsay库[https://ss64.com/osx/say.html]</a></p>
</li>
<li><p>STT处理：使用witai</p>
<blockquote>
<p>chosen according to code availability and whether it’s freely available or has high daily usage limitations</p>
</blockquote>
</li>
</ul>
<p>不同处理方式在单词缺失和错误的比例不同</p>
<p>使用iBLEU来表示noise的程度，iBLEU在[0,1]取值</p>
<p>iBLEU=1-BLEU</p>
<p>BLEU是机器翻译任务中经常使用的指标</p>
<p><img src="G:\MyBlog\AdamFocus.github.io\img\TTS-STT对比.jpg"></p>
<h3 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h3><h4 id="baseline："><a href="#baseline：" class="headerlink" title="baseline："></a>baseline：</h4><ol>
<li><p>bert</p>
</li>
<li><p>NLU service platforms：[Google Dialogflow (formerly Api.ai)][<a href="https://dialogflow.com],[">https://dialogflow.com],[</a> SAP Conversational AI (formerly<br>Recast.ai)][<a href="https://cai.tools.sap]and">https://cai.tools.sap]and</a> [Rasa (spacy and tensorflow backend)][<a href="https://rasa.com]">https://rasa.com]</a>.</p>
</li>
<li><p>Semantic hashing with classifier</p>
<p>Subword semantic hashing for intent classification on small datasets提到的一种word embedding方法，不会受到out-of-vocabulary的影响，使用在字母表的hash token而不是单个词语，使得vocabulary更加独立。</p>
<p>分类器使用多层感知机、svm和随机森林</p>
</li>
</ol>
<h4 id="train"><a href="#train" class="headerlink" title="train"></a>train</h4><ol>
<li><p>intent classification任务：</p>
<p>一共训练三次，分别为完整数据、两种TTS-STT结合生成的数据</p>
</li>
<li><p>情感分析任务：</p>
<p>一共训练三次，分别为original text、corrected text、incorrect with correct texts</p>
<p>选取十次中最好的F1值</p>
</li>
<li><p>Semantic hashing with classifier设置：</p>
<p>采用3-gram，特征向量size设置为768</p>
<p>13种分类器参数按照论文内容设置</p>
</li>
<li><p>bert设置：</p>
<p>12 transformer block L</p>
<p>hidden size H-768</p>
<p>12 self-attention heads A</p>
<p>3 epochs with Adam Optimizer</p>
<p>learning rate of 2 ∗ 10−5</p>
<p>maximum sequence length -128</p>
<p>warm up proportion - 0.1</p>
<p>train batch size is 4 for the Twitter Sentiment Corpus and 8 for the Chatbot Intent Classification Corpus</p>
</li>
<li><p>Stacked DeBert设置：</p>
<p>trained in end-to-end manner</p>
<p>training time depending on the size of the dataset and train batch size</p>
<p>The stack of multilayer perceptrons are trained for 100 and 1,000 epochs with Adam Optimizer</p>
<p>learning rate of 10−3,</p>
<p>weight decay of 10−5,</p>
<p>MSE loss criterion and batch size the same as BERT (4 for the Twitter Sentiment<br>Corpus and 8 for the Chatbot Intent Classification Corpus).</p>
</li>
</ol>
<h3 id="RESULT"><a href="#RESULT" class="headerlink" title="RESULT"></a>RESULT</h3><p>准确率</p>
<p>F1值</p>
<p>混淆矩阵</p>
<h3 id="未来工作"><a href="#未来工作" class="headerlink" title="未来工作"></a>未来工作</h3><p>针对其他类型的噪声，比如单词重新排序，单词插入，拼写错误等等</p>
<p>使用其他网络代替前馈神经网络</p>

      
    </div>
    <footer class="article-footer">
      
      
      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/08/02/Pruning%20and%20Sparsemax%20Methods%20for%20Hierarchical%20Attention%20Networks%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          Pruning and Sparsemax Methods for Hierarchical Attention Networks
        
      </div>
    </a>
  
  
    <a href="/2020/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93(%E4%B8%80)/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">机器学习知识点总结(一)</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
        <ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1%E5%88%86%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">任务分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%86%E5%8F%B2%E5%B7%A5%E4%BD%9C"><span class="nav-number">2.</span> <span class="nav-text">历史工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E5%B7%A5%E4%BD%9C"><span class="nav-number">3.</span> <span class="nav-text">本文工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model"><span class="nav-number">4.</span> <span class="nav-text">Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%B8%B8%E8%A7%84Bert%E5%B1%82"><span class="nav-number">4.1.</span> <span class="nav-text">1.常规Bert层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Denoising-transformer%EF%BC%9A"><span class="nav-number">4.2.</span> <span class="nav-text">2.Denoising transformer：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-feedforward-network-softmax-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">4.3.</span> <span class="nav-text">3.feedforward network&#x2F;softmax 激活函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.</span> <span class="nav-text">使用的数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-Twitter-Sentiment-Classification"><span class="nav-number">5.1.</span> <span class="nav-text">1. Twitter Sentiment Classification</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Chatbot-Natural-Language-Unerstanding-NLU-Evaluation-Corpus"><span class="nav-number">5.2.</span> <span class="nav-text">2.Chatbot Natural Language Unerstanding (NLU) Evaluation Corpus</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E9%83%A8%E5%88%86"><span class="nav-number">6.</span> <span class="nav-text">实验部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#baseline%EF%BC%9A"><span class="nav-number">6.1.</span> <span class="nav-text">baseline：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#train"><span class="nav-number">6.2.</span> <span class="nav-text">train</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RESULT"><span class="nav-number">7.</span> <span class="nav-text">RESULT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C"><span class="nav-number">8.</span> <span class="nav-text">未来工作</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2021 - 2022 Adam&#39;s Blog All Rights Reserved.</p>
	      
	      
  		   	<p id="copyRightCn">Adam Focus 保留所有权利</p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/scripts.js"></script>





  
<script src="/js/dialog.js"></script>















  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Adam&#39;s Blog
          </div>
          <div class="panel-body">
            Copyright © 2022 Adam Focus All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>
<!-- 页面点击小红心 -->
{% if theme.clicklove %}
      <script type="text/javascript" src="/js/clicklove.js"></script>
{% endif %}